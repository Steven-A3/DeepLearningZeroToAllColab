{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab-11-5-fashion_mnist_cnn_ensemble_layers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steven-A3/DeepLearningZeroToAllColab/blob/master/lab_11_5_fashion_mnist_cnn_ensemble_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuF11IW6JXyb",
        "colab_type": "code",
        "outputId": "48783756-4693-4f72-cfa9-d5d7b6c5f64d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Lab 11 MNIST and Deep learning CNN\n",
        "# https://www.tensorflow.org/tutorials/layers\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNHVWDprT43Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiZngcgCT9Y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_all: (60000, 28, 28)\n",
        "y_train_all: (60000,)\n",
        "x_test: (10000, 28, 28)\n",
        "y_test: (10000,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNwFM0YTTcl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "\n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkUpvb8kUMmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train_all.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlCrWWazUpz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vqn-QPHUw5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train_all)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2mu-QHBJfVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "f8512e28-65af-4d2b-af49-03309947ae9a"
      },
      "source": [
        "# hyper parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 20\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
        "            # for testing\n",
        "            self.training = tf.placeholder(tf.bool)\n",
        "\n",
        "            # input place holders\n",
        "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "            # img 28x28x1 (black/white), Input Layer\n",
        "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
        "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            # Convolutional Layer #1\n",
        "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            # Pooling Layer #1\n",
        "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
        "                                         rate=0.7, training=self.training)\n",
        "\n",
        "            # Convolutional Layer #2 and Pooling Layer #2\n",
        "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
        "                                         rate=0.7, training=self.training)\n",
        "\n",
        "            # Convolutional Layer #3 and Pooling Layer #3\n",
        "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
        "                                         rate=0.7, training=self.training)\n",
        "\n",
        "            # Dense Layer with Relu\n",
        "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
        "            dense4 = tf.layers.dense(inputs=flat,\n",
        "                                     units=625, activation=tf.nn.relu)\n",
        "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
        "                                         rate=0.5, training=self.training)\n",
        "\n",
        "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
        "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
        "\n",
        "        # define cost/loss & optimizer\n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=self.logits, labels=self.Y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(\n",
        "            learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(\n",
        "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, training=False):\n",
        "        return self.sess.run(self.logits,\n",
        "                             feed_dict={self.X: x_test, self.training: training})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, training=False):\n",
        "        return self.sess.run(self.accuracy,\n",
        "                             feed_dict={self.X: x_test,\n",
        "                                        self.Y: y_test, self.training: training})\n",
        "\n",
        "    def train(self, x_data, y_data, training=True):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
        "            self.X: x_data, self.Y: y_data, self.training: training})\n",
        "\n",
        "# initialize\n",
        "sess = tf.Session()\n",
        "\n",
        "models = []\n",
        "num_models = 2\n",
        "for m in range(num_models):\n",
        "    models.append(Model(sess, \"model\" + str(m)))\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Learning Started!')\n",
        "\n",
        "# train my model\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost_list = np.zeros(len(models))\n",
        "    total_batch = int(len(x_train) / batch_size)\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = next_batch(batch_size, x_train, y_train)\n",
        "\n",
        "        # train each model\n",
        "        for m_idx, m in enumerate(models):\n",
        "            c, _ = m.train(batch_xs, batch_ys)\n",
        "            avg_cost_list[m_idx] += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
        "\n",
        "print('Learning Finished!')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-40816a489870>:28: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-8-40816a489870>:31: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:From <ipython-input-8-40816a489870>:33: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:From <ipython-input-8-40816a489870>:54: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-8-40816a489870>:63: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Learning Started!\n",
            "Epoch: 0001 cost = [0.92266331 0.91089056]\n",
            "Epoch: 0002 cost = [0.61282102 0.60497393]\n",
            "Epoch: 0003 cost = [0.54578002 0.54025757]\n",
            "Epoch: 0004 cost = [0.51237421 0.5075143 ]\n",
            "Epoch: 0005 cost = [0.4893516  0.48439262]\n",
            "Epoch: 0006 cost = [0.46419268 0.46238895]\n",
            "Epoch: 0007 cost = [0.45882277 0.45863367]\n",
            "Epoch: 0008 cost = [0.45115953 0.44555587]\n",
            "Epoch: 0009 cost = [0.43517385 0.43414425]\n",
            "Epoch: 0010 cost = [0.4290485 0.4334593]\n",
            "Epoch: 0011 cost = [0.41604541 0.41777358]\n",
            "Epoch: 0012 cost = [0.42095475 0.41801495]\n",
            "Epoch: 0013 cost = [0.40852457 0.4128791 ]\n",
            "Epoch: 0014 cost = [0.41075021 0.40778672]\n",
            "Epoch: 0015 cost = [0.40879532 0.41323441]\n",
            "Epoch: 0016 cost = [0.40508976 0.40637364]\n",
            "Epoch: 0017 cost = [0.40679061 0.41034142]\n",
            "Epoch: 0018 cost = [0.40017721 0.4040058 ]\n",
            "Epoch: 0019 cost = [0.39830486 0.39745402]\n",
            "Epoch: 0020 cost = [0.39996387 0.39751994]\n",
            "Learning Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRSSAplFXoAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "95f0f7ff-8218-4c68-bc35-fb9ee72d2731"
      },
      "source": [
        "# Test model and check accuracy\n",
        "test_size = len(x_test)\n",
        "predictions = np.zeros([test_size, 10])\n",
        "for m_idx, m in enumerate(models):\n",
        "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
        "        x_test, y_test))\n",
        "    p = m.predict(x_test)\n",
        "    predictions += p\n",
        "\n",
        "ensemble_correct_prediction = tf.equal(\n",
        "    tf.argmax(predictions, 1), tf.argmax(y_test, 1))\n",
        "ensemble_accuracy = tf.reduce_mean(\n",
        "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
        "print('Ensemble accuracy:', sess.run(ensemble_accuracy))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Accuracy: 0.8777\n",
            "1 Accuracy: 0.8758\n",
            "Ensemble accuracy: 0.8799\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}